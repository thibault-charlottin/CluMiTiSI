{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11956fed",
   "metadata": {},
   "source": [
    "<h1><span style=\"color:blue\">Toward a warranty of micro-simulators for mixed traffic assessement: <br> \n",
    "    can we pass the prerequirement of test-cases definition? </span></h1> \n",
    "\n",
    "CLUMITISI: Clustering Mixed Traffic Situations <br> \n",
    "@author: Thibault Charlottin <br>\n",
    "@contributor: Christine Buisson <br>\n",
    "Licit-Eco7, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c67bb0",
   "metadata": {},
   "source": [
    "This script is devoted to realize simulations corresponding to a wide variety of freeway mixed (Automated Cruise Control and Human Driven Vehicles) traffic situations and to cluster them with three classical clustering methods. The script is working on top of the Sumo code that you must install (in the Windows version) before processing the current script.\n",
    "\n",
    "The first part allows you to create simulations on SUMO with two car-following models and to compute them. In the second and third parts you can analyse and cluster obtained data.\n",
    "\n",
    "It was developped by Thibault Charlottin during his master internship April-August 2022, under the supervision of Christine Buisson in the LICIT-ECO7 Lab, in Lyon, France. https://licit-lyon.eu/\n",
    "\n",
    "It is divided into parts:<br>\n",
    "- 1st part: file simulation using Traci module \n",
    "- 2nd part: indicators definition and computation\n",
    "- 3rd part: indicator clustering and plot editing<br>\n",
    "\n",
    "SUMO can be downloaded for windows version (the only one working with this code) at\n",
    "    https://sumo.dlr.de/docs/Downloads.php\n",
    "\n",
    "This source is provided upon the Eclipse Public License 2.0 (see: https://www.eclipse.org/legal/epl-2.0/)\n",
    "\n",
    "In the following, the comments are in English but some of the variables names are in French.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1adfd90",
   "metadata": {},
   "source": [
    "**Warning #1 the Traci librairies are Windows based, the simulation section won't work on Mac**<br>\n",
    "**Warning #2 this code not tested on Linux distributions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107620af",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Setup : libraires and paths</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e385e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "#SUMO libraries ! NOTE THAT YOU CANNOT USE THOSE LIBRARIES ON MAC !\n",
    "import traci\n",
    "import traci.constants as tc\n",
    "import pysumo as pysumo\n",
    "\n",
    "#handle data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#plots libraries\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib.colors import LogNorm\n",
    "import plotly.express as px\n",
    "\n",
    "#machine learning libraries\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from kneed import KneeLocator\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#misc libraries\n",
    "import random as rd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from time import time\n",
    "from multiprocessing import Process, Pool\n",
    "from alive_progress import alive_bar\n",
    "from numba import jit, cuda\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a751372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set plot style\n",
    "sns.set_theme()\n",
    "%matplotlib inline\n",
    "plt.rc('xtick', labelsize=20) \n",
    "plt.rc('ytick', labelsize=20) \n",
    "warnings.filterwarnings('ignore') #to disable warnings in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a9a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global path TO BE CHANGE ACCORDINGLY TO YOUR WORKPATH\n",
    "#we advise you to use this path to store all the files you will use and create during this script\n",
    "global_path = \"C:/Users/tchar/Downloads/simulation files and code/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6df0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUMO path\n",
    "#mandatory for using the Traci module\n",
    "sumoBinary = \"C:/Program Files (x86)/Eclipse/Sumo/bin/sumo.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d75c7",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Import the input files</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f931626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening csv files that contains the names of all files\n",
    "df_section_Krauss = pd.read_csv(global_path+\"inputs/inputs Krauss.csv\", delimiter=';')\n",
    "df_section_EIDM = pd.read_csv(global_path+\"inputs/inputs EIDM.csv\", delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0e6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting all simulation files that might be in the folder so that we get an updated version\n",
    "models_list = ['krauss','EIDM']\n",
    "for k in models_list :\n",
    "    dir = global_path+'simulations/'+ k +'/'\n",
    "    for f in os.listdir(dir):\n",
    "        os.remove(os.path.join(dir, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585e0be",
   "metadata": {},
   "source": [
    "In the following cell, please note that the lines within the 'lines to change' are to be modified accordingly to the local path you used for the downloaded input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d431fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that creates the sumocfg files\n",
    "#please note that the lines within the 'lines to change' are to be modified accordingly to your local path\n",
    "def export_sumogfg(df,geometry, replication, model):\n",
    "    for k in range(len(df['combis géométrie'])):\n",
    "        if df['combis géométrie'][k]!='NaN':\n",
    "            for l in range(len(df['combis demande'])):\n",
    "                #changing filenames to the imposed SUMO format\n",
    "                geom = str(df['combis géométrie'][k])  #network files             \n",
    "                traf = str(df['combis demande'][l])    #route files\n",
    "                geom = geom.replace(\".net.xml\", \"\")   #cleaning the names\n",
    "                traf = traf.replace(\".rou.xml\", \"\")   #cleaning the names\n",
    "                doc_out=global_path+'/simulations/'+ model +'/' +geom+'_'+traf+''+model+'.sumocfg' #export path\n",
    "                #writting the XML file \n",
    "                xml=['<configuration xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\" xsi:noNamespaceSchemaLocation=\\\"http://sumo.dlr.de/xsd/sumoConfiguration.xsd\\\">']\n",
    "                xml.append('\\n  <input>')\n",
    "                #defining the path for input files\n",
    "                #******LINES TO CHANGE ACCORDINGLY TO YOUR LOCAL PATH******\n",
    "                xml.append('\\n    <net-file value=\\\"' + \"C:\"+\"\\\\\"+\"Users\"+\"\\\\\"+\"tchar\"+\"\\\\\"+\"Downloads\"+\"\\\\\"+\"simulation files and code\"+\"\\\\\"+\"inputs\"+\"\\\\\" +model+'\\\\'  + 'network' + '\\\\' + str(df['combis géométrie'][k]) + '\\\"/>')\n",
    "                xml.append('\\n    <route-files value=\\\"' + \"C:\"+\"\\\\\"+\"Users\"+\"\\\\\"+\"tchar\"+\"\\\\\"+\"Downloads\"+\"\\\\\"+\"simulation files and code\"+'\\\\'+\"inputs\"+\"\\\\\"+model+'\\\\'  +  'route' + '\\\\' + str(df['combis demande'][l]) + '\\\"/>')\n",
    "                #****** END OF LINES TO CHANGE ACCORDINGLY TO YOUR LOCAL PATH******\n",
    "                xml.append('\\n  </input>')\n",
    "                xml.append('\\n  ')\n",
    "                #defining the simulation lenght and the timestep\n",
    "                xml.append('\\n  <time>')\n",
    "                xml.append('\\n    <begin value=\\\"0\\\"/>')\n",
    "                xml.append('\\n    <end value=\"3600\"/>')\n",
    "                xml.append('\\n    <step-length value=\"1\"/>')\n",
    "                xml.append('\\n  </time>')             \n",
    "                xml.append('\\n\\t</configuration>')\n",
    "                with open(doc_out, 'w') as f:  # Writing the .sumocgf file\n",
    "                    for line in xml:\n",
    "                        f.write(line)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b21e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_sumogfg(df_section_EIDM,'section', 10,'EIDM')\n",
    "export_sumogfg(df_section_Krauss,'section', 10,'krauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9385fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some files does not correspond to anything due to the shape of the csv file let's delete them\n",
    "models = ['EIDM','krauss']\n",
    "for k in models :\n",
    "    files = os.listdir(global_path+'/simulations/' + k + '/')\n",
    "    for file_name in files:\n",
    "    # construct full file path\n",
    "        filename = os.path.join(global_path+'/simulations/' + k + '/', file_name)\n",
    "        if 'nan' in filename :\n",
    "            os.remove(os.path.join(dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a886c9",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> First part: simulating</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf4bdd6",
   "metadata": {},
   "source": [
    "This part use the .sumocfg files we just created as inputs <br>\n",
    "output is a dataframe for each simulation containing car ID, car lenght lattitude, logitude , speed, acceleration for each timestep <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fe9a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_path_section_krauss = global_path + \"simulations/krauss/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e51a1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_path_section_EIDM = global_path + \"simulations/EIDM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9102c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run simulation\n",
    "def running_simulation(simulation_file, simulation_lenght,path_out, sim_name, replication_number):\n",
    "    sumoCmd = [sumoBinary, \"-c\", simulation_file,\"--start\",\"--quit-on-end\", '--random', '--no-step-log']\n",
    "    step = 0\n",
    "    #defining variables to be save\n",
    "    timestep = []\n",
    "    IDs = []\n",
    "    speed = []\n",
    "    acceleration = []\n",
    "    x_position = []\n",
    "    y_position = []\n",
    "    lane = []\n",
    "    lenght = []\n",
    "    time_start = time()\n",
    "    traci.start(sumoCmd)\n",
    "    for j in range(simulation_lenght):\n",
    "        #executting SUMO\n",
    "        traci.simulationStep()\n",
    "        at_t_IDs = traci.vehicle.getIDList()\n",
    "        at_t_IDs= [*at_t_IDs]\n",
    "        at_t_positions = [traci.vehicle.getPosition(id) for id in traci.vehicle.getIDList()]\n",
    "        at_t_acceleration = [traci.vehicle.getAcceleration(id) for id in traci.vehicle.getIDList()]      \n",
    "        at_t_lane = [traci.vehicle.getLaneID(id) for id in traci.vehicle.getIDList()]\n",
    "        at_t_speed = [traci.vehicle.getSpeed(id) for id in traci.vehicle.getIDList()]\n",
    "        at_t_lenght = [traci.vehicle.getLength(id) for id in traci.vehicle.getIDList()]\n",
    "        #traci doesn't save the variables we have do it ourselve\n",
    "        for k in range(len(at_t_speed)) : \n",
    "        #saving data for each timestep\n",
    "            timestep.append(j)\n",
    "            IDs.append(at_t_IDs[k])\n",
    "            x_position.append(at_t_positions[k][0])\n",
    "            y_position.append(at_t_positions[k][1])\n",
    "            acceleration.append(at_t_acceleration[k])\n",
    "            speed.append(at_t_speed[k])\n",
    "            lenght.append(at_t_lenght[k])\n",
    "            lane.append(at_t_lane[k])\n",
    "    traci.close()\n",
    "    #saving simualtion result in a dataframe\n",
    "    df = pd.DataFrame({'timestep' : timestep, 'ID' : IDs,'lenght' : lenght,'lane': lane,'x' : x_position,'y' : y_position, 'acceleration' : acceleration, 'speed' : speed})\n",
    "    time_end = time()\n",
    "    df.to_csv(path_out+' '+ str(sim_name) + 'EIDM model replication num '+str(replication_number)+'.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "935c3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to run the simulation at the scale of a whole folder\n",
    "def simulating_all_the_files (path,path_out,simulation_lenght) : \n",
    "    fichiers = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    counter = 0\n",
    "    #on simule tous les .sumocfg du dossier\n",
    "    for filename in glob.glob(os.path.join(path, '*.sumocfg')):\n",
    "            for k in tqdm_notebook(range(10), desc = 'simulating' + str(fichiers[counter])):\n",
    "                running_simulation (filename, 3600, path_out, fichiers[counter], k)\n",
    "            print('scenario ' + str(fichiers[counter]) + ' has been fully simulated 10 times')\n",
    "            counter += 1\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f83fd7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd52f017c944effab7c5de8393f6959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "simulatingReseau section 3 voies brouillard_2200 0 ACCkrauss.sumocfg:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TraCIException",
     "evalue": "Connection 'default' is already active.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTraCIException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5024/3979848978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#we run 10 replication with a 1h lenght\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobal_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"output/Krauss/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msimulating_all_the_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulation_path_section_krauss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5024/1582818293.py\u001b[0m in \u001b[0;36msimulating_all_the_files\u001b[1;34m(path, path_out, simulation_lenght)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.sumocfg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'simulating'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfichiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0mrunning_simulation\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfichiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'scenario '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfichiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' has been fully simulated 10 times'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5024/4019359392.py\u001b[0m in \u001b[0;36mrunning_simulation\u001b[1;34m(simulation_file, simulation_lenght, path_out, sim_name, replication_number)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mlenght\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtime_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtraci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msumoCmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulation_lenght\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#executting SUMO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\main.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(cmd, port, numRetries, label, verbose, traceFile, traceGetters, stdout, doSwitch)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \"\"\"\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_connections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTraCIException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Connection '%s' is already active.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraceFile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0m_startTracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraceFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceGetters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTraCIException\u001b[0m: Connection 'default' is already active."
     ]
    }
   ],
   "source": [
    "#simulating for the sections with EIDM model\n",
    "#we run 10 replication with a 1h lenght \n",
    "path_out = global_path + \"output/Krauss/\"\n",
    "simulating_all_the_files(simulation_path_section_krauss,path_out,3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011147c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulating for the merging with Krauss Model\n",
    "#we run 10 replication with a 1h lenght \n",
    "path_out = global_path + \"output/EIDM/\"\n",
    "simulating_all_the_files(simulation_path_section_EIDM,path_out,3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c91353",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Second part: computing indicators</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a933072",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Import results</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining results path\n",
    "results_path_section_Krauss = global_path + \"output/Krauss/\"\n",
    "results_path_section_EIDM = global_path + \"output/EIDM/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_car_trajectories(dataframe,variables, car_number_list, color_list,namelist):\n",
    "    #to visualise one's car trajectory from his network injection to his network departure\n",
    "    palette = itertools.cycle(sns.color_palette()) \n",
    "    for k in range(len(car_number_list)) :\n",
    "        fig, axs = plt.subplots(len(car_number_list[k]), len(variables),figsize=(60,60)) #creating a subplot\n",
    "        for i in range(len(car_number_list[k])):\n",
    "            filtered_df = dataframe[dataframe.ID == car_number_list[k][i]]\n",
    "            c = next(palette) \n",
    "            for j in range(len(variables)) :\n",
    "                legend = \"veh name = \" + str(car_number_list[k][i])\n",
    "                \n",
    "                axs[i,j].plot(filtered_df['timestep'],filtered_df[variables[j]], color = c, linewidth=10)\n",
    "                axs[i,j].set_xlabel('time (s)', fontsize = 50.0)\n",
    "                axs[i,j].set_ylabel(namelist[j], fontsize = 50)\n",
    "                axs[i,j].set_title( \"car: \" + str(car_number_list[k][i]) + \" \" + namelist[j] + ' over time', fontsize = 60)\n",
    "                axs[i,j].tick_params(axis='x',labelsize=40)\n",
    "                axs[i,j].tick_params(axis='y',labelsize=40)\n",
    "                \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc40eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to plot some trajectories\n",
    "#car-number_list = [f_0.0]\n",
    "#color_list = ['blue']\n",
    "#variables = ['speed']\n",
    "#namelist = = ['speed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7c78d",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Creating new indicators</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ea32c",
   "metadata": {},
   "source": [
    "We create 3 indicators: <br>\n",
    "- spacing\n",
    "- intervehicular time\n",
    "- time to Collision <br>\n",
    "please refer to the article for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_traffic_indicators(DataFrame) : \n",
    "    DataFrame = DataFrame.sort_values(['timestep','x'],ascending=True) #sorting dataframe by position for each car for each timestep\n",
    "    #importing results that we need to compute them into indicators\n",
    "    speed = DataFrame['speed']\n",
    "    ID = DataFrame['ID']\n",
    "    lane = DataFrame['lane'] \n",
    "    timestep = DataFrame['timestep']\n",
    "    lenght = DataFrame['lenght']\n",
    "    acceleration = DataFrame['acceleration']\n",
    "    x = DataFrame['x']\n",
    "    y = DataFrame['y']\n",
    "    #creating lists to save computed indicators\n",
    "    spacing_list = [np.nan]\n",
    "    IVT_list =[np.nan]\n",
    "    for k in tqdm_notebook(range(1,len(ID))):\n",
    "        #compute Traffic indicators (based on n-1th car)\n",
    "        if lane[k] == lane[k-1] and timestep[k] == timestep[k-1] :\n",
    "            space = np.sqrt((abs(x[k-1]-x[k]))**2 + ((abs(y[k-1]-y[k]))**2))\n",
    "            spacing_list.append(space)\n",
    "            if  speed[k-1]>speed[k]:\n",
    "                TTC_list.append(space/(speed[k-1]-speed[k]))\n",
    "            else : \n",
    "                TTC_list.append(np.nan)\n",
    "        else : \n",
    "            spacing_list.append(np.nan)\n",
    "            TTC_list.append(np.nan)\n",
    "    DataFrame['spacing'] = spacing_list\n",
    "    DataFrame['TTC'] = TTC_list\n",
    "    return DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_20ile(DataFrame, out_DataFrame_spacing,out_DataFrame_IVT,out_DataFrame_TTC, out_DataFrame_power , out_name) :\n",
    "    #transforming indicators distributions into twentiles\n",
    "    #by default the twentile will be the only indicators results saved for RAM efficiency\n",
    "    DataFrame = compute_traffic_indicators(DataFrame) #create the twentiles\n",
    "    spacing_list = DataFrame['spacing']\n",
    "    TTC_list = DataFrame['TTC']\n",
    "    spacing_20ile = np.nanpercentile(spacing_list, np.arange(0, 100, 5))\n",
    "    TTC_20ile = np.nanpercentile(TTC_list, np.arange(0, 100, 5))\n",
    "    out_DataFrame_spacing[out_name] = spacing_20ile\n",
    "    out_DataFrame_IVT[out_name] = IVT_20ile\n",
    "    out_DataFrame_TTC[out_name] = TTC_20ile\n",
    "    out_DataFrame_power[out_name] = power_20ile\n",
    "    return out_DataFrame_spacing, out_DataFrame_IVT, out_DataFrame_TTC, out_DataFrame_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01120ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_DataFrame_spacing= pd.DataFrame()\n",
    "out_DataFrame_IVT = pd.DataFrame()\n",
    "out_DataFrame_TTC = pd.DataFrame()\n",
    "out_DataFrame_power = pd.DataFrame()\n",
    "paths = [results_path_section_Krauss]\n",
    "#computing Krauss model section twentiles indicators \n",
    "for k in paths : \n",
    "    files = os.listdir(k)\n",
    "    lenght = len(files)\n",
    "    for file_name in tqdm_notebook(range(lenght)):\n",
    "        df = pd.read_csv(k+files[file_name])\n",
    "        print(files[file_name])\n",
    "        out_DataFrame_spacing, out_DataFrame_IVT, out_DataFrame_TTC, out_DataFrame_power  =compute_20ile(df, out_DataFrame_spacing,out_DataFrame_IVT,out_DataFrame_TTC ,out_DataFrame_power, files[file_name] )\n",
    "DataFrame_spacing_Krauss = out_DataFrame_spacing.copy()\n",
    "DataFrame_IVT_Krauss = out_DataFrame_IVT.copy()\n",
    "DataFrame_TTC_Krauss = out_DataFrame_TTC.copy()\n",
    "DataFrame_power_Krauss = out_DataFrame_power.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_DataFrame_spacing= pd.DataFrame()\n",
    "out_DataFrame_IVT = pd.DataFrame()\n",
    "out_DataFrame_TTC = pd.DataFrame()\n",
    "out_DataFrame_power = pd.DataFrame()\n",
    "paths = [results_path_section_EIDM]\n",
    "#computing EIDM model section twentiles indicators \n",
    "for k in paths : \n",
    "    files = os.listdir(k)\n",
    "    lenght = len(files)\n",
    "    for file_name in tqdm_notebook(range(lenght)):\n",
    "        df = pd.read_csv(k+files[file_name])\n",
    "        print(files[file_name])\n",
    "        out_DataFrame_spacing, out_DataFrame_IVT, out_DataFrame_TTC, out_DataFrame_power  =compute_20ile(df, out_DataFrame_spacing,out_DataFrame_IVT,out_DataFrame_TTC ,out_DataFrame_power, files[file_name] )\n",
    "DataFrame_spacing_EIDM = out_DataFrame_spacing.copy()\n",
    "DataFrame_IVT_EIDM = out_DataFrame_IVT.copy()\n",
    "DataFrame_TTC_EIDM = out_DataFrame_TTC.copy()\n",
    "DataFrame_power_EIDM = out_DataFrame_power.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d5e37",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Third part: clustering </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde53e65",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> DBscan clustering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225cffa",
   "metadata": {},
   "source": [
    "First we compute a DBscan clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBscan_clustering(DataFrame, minsample, eps) :\n",
    "    DataFrame = DataFrame.transpose()\n",
    "    X = DataFrame.values\n",
    "    dbscan_cluster = DBSCAN(eps=eps, min_samples=minsample)\n",
    "    dbscan_cluster.fit(X)\n",
    "    labels = dbscan_cluster.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise_ = list(labels).count(-1)\n",
    "    results = dbscan_cluster.labels_\n",
    "    return results, n_clusters_, n_noise_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_based_on_epsilon(eps_list, df_list, name_columns, indicator_name, tick_list):\n",
    "    names = list(df_list[0].T.index)\n",
    "    DB_cluster_DataFrame= pd.DataFrame(names)\n",
    "    DB_cluster_DataFrame.columns = ['scenario']\n",
    "    nb_minsample_list = [100,100]\n",
    "    cluster_nb_list_EIDM = []\n",
    "    noise_list_EIDM = []\n",
    "    cluster_nb_list_Krauss = []\n",
    "    noise_list_Krauss = []\n",
    "    for l in range (len(eps_list)):\n",
    "        for k in range (len(df_list)) : \n",
    "            results, n_clusters_, n_noise_ = DBscan_clustering(df_list[k], nb_minsample_list[k], eps_list[l])\n",
    "            if k == 0:\n",
    "                cluster_nb_list_EIDM.append(n_clusters_)\n",
    "                noise_list_EIDM.append(n_noise_/len(df_list[k].columns)*100)\n",
    "            else : \n",
    "                cluster_nb_list_Krauss.append(n_clusters_)\n",
    "                noise_list_Krauss.append(n_noise_/len(df_list[k].columns)*100)\n",
    "    fig, ax = plt.subplots(2, 1,sharex=True,figsize=(30,30))\n",
    "    ax[0].plot(eps_list,cluster_nb_list_EIDM,linewidth = 5, label = 'EIDM model')\n",
    "    ax[0].plot(eps_list,cluster_nb_list_Krauss,':',linewidth = 5, label = 'Krauss model')\n",
    "    ax[0].legend( prop={'size': 40})\n",
    "    ax[0].set_ylabel('number of clusters', size = 35)    \n",
    "    ax[0].set_title(' number of '+ indicator_name + ' clusters using DBscan depending on the epsilon value', size = 45)\n",
    "    ax[0].set_yticklabels(tick_list, fontsize = 35)\n",
    "    ax[1].bar(eps_list,noise_list_EIDM, label = 'EIDM model',width  = 0.5)\n",
    "    Kraussbars = [x + 0.5 for x in eps_list]\n",
    "    ax[1].bar(Kraussbars,noise_list_Krauss, label = 'Krauss model',width = 0.5)\n",
    "    ax[1].set_xlabel('epsilon', size = 35)       \n",
    "    ax[1].set_ylabel('percentage of outliers', size = 35)    \n",
    "    ax[1].set_title('number of '+ indicator_name + '  outliers using DBscan depending on the epsilon value', size = 45)\n",
    "    ax[1].legend( prop={'size': 40})\n",
    "    plt.xticks(fontsize=35)\n",
    "    plt.yticks(fontsize=35)\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_EIDM_spacing, df_Krauss_spacing]\n",
    "name_columns = ['EIDM spacing','Krauss spacing']\n",
    "eps_list = [k for k in range(1,45)]\n",
    "indicator_name = 'spacing'\n",
    "tick_list = [k for k in range (0,10)]\n",
    "plot_based_on_epsilon(eps_list, df_list, name_columns, indicator_name, tick_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd49ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_EIDM_TTC, df_Krauss_TTC]\n",
    "name_columns = ['EIDM TTC','Krauss TTC']\n",
    "eps_list = [k for k in range(1,45)]\n",
    "indicator_name = 'TTC'\n",
    "tick_list = [k for k in range (0,10)]\n",
    "plot_based_on_epsilon(eps_list, df_list, name_columns, indicator_name, tick_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27011eeb",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Kmeans clustering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10e51e",
   "metadata": {},
   "source": [
    "Then we compute Kmeans clustering, to determine the ideal cluster number we use the WCSS elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choosing_cluster_number(DataFrame):\n",
    "    wcss = []\n",
    "    for i in range(1,11):\n",
    "        model = KMeans(n_clusters = i, init = 'k-means++')\n",
    "        model.fit(DataFrame)\n",
    "        wcss.append(model.inertia_)\n",
    "    return wcss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [DataFrame_EIDM_spacing, DataFrame_EIDM_TTC, DataFrame_Krauss_spacing, DataFrame_Krauss_TTC]\n",
    "name_columns = ['EIDM spacing', 'EIDM TTC','EIDM spacing', 'EIDM TTC']\n",
    "names = list(DataFrame_spacing.T.index)\n",
    "cluster_DataFrame= pd.DataFrame(names)\n",
    "cluster_DataFrame.columns = ['scenario']\n",
    "fig, axs = plt.subplots(2, 2,figsize=(30,30)) #creating a subplot \n",
    "wcss = choosing_cluster_number(DataFrame_EIDM_spacing)\n",
    "axs[0,0].plot(list(k for k in range(1,11)), wcss)\n",
    "axs[0,0].set_xlabel('number of clusters', size = 20)\n",
    "axs[0,0].set_ylabel('WCSS', size = 20)\n",
    "axs[0,0].set_title('EIDM spacing', size = 20)\n",
    "wcss = choosing_cluster_number(DataFrame_EIDM_TTC)\n",
    "axs[0,1].plot(list(k for k in range(1,11)), wcss)\n",
    "axs[0,1].set_xlabel('number of clusters', size = 20)\n",
    "axs[0,1].set_ylabel('WCSS', size = 20)\n",
    "axs[0,1].set_title('EIDM TTC', size = 20)\n",
    "wcss = choosing_cluster_number(DataFrame_Krauss_spacing)\n",
    "axs[1,0].plot(list(k for k in range(1,11)), wcss)\n",
    "axs[1,0].set_xlabel('number of clusters', size = 20)\n",
    "axs[1,0].set_ylabel('WCSS', size = 20)\n",
    "axs[1,0].set_title('Krauss spacing', size = 20)\n",
    "wcss = choosing_cluster_number(DataFrame_Krauss_TTC)\n",
    "axs[1,1].plot(list(k for k in range(1,11)), wcss)\n",
    "axs[1,1].set_xlabel('number of clusters', size = 20)\n",
    "axs[1,1].set_ylabel('WCSS', size = 20)\n",
    "axs[1,1].set_title('Krauss TTC', size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d556f1",
   "metadata": {},
   "source": [
    "The elbow method gives us 5 clusters to be created for the spacing indicator and 3 for the TTC indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda44db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_data(DataFrame, clusters) : \n",
    "    #function to cluster using kmeans algorithm\n",
    "    model = MiniBatchKMeans(n_clusters= clusters)\n",
    "    labels = model.fit_predict(DataFrame) #apply kmeans to the twentile dataframe\n",
    "    results = pd.DataFrame([DataFrame.index,labels]).T\n",
    "    results.columns = ['scenario', 'label'] #creating a dataframe that computes the cluster assigned to a sample\n",
    "    centers = np.array(model.cluster_centers_) #exporting kmeans centroids\n",
    "    closest, _ = pairwise_distances_argmin_min(model.cluster_centers_, DataFrame)\n",
    "    return results, centers, closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19518aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [DataFrame_EIDM_spacing, DataFrame_EIDM_TTC, DataFrame_Krauss_spacing, DataFrame_Krauss_TTC]\n",
    "name_columns = ['EIDM spacing', 'EIDM TTC','Krauss spacing', 'Krauss TTC']\n",
    "names = list(DataFrame_EIDM_spacing.T.index)\n",
    "cluster_DataFrame_kmeans= pd.DataFrame(names)\n",
    "cluster_DataFrame_kmeans.columns = ['scenario']\n",
    "nb_cluster_list = [5,3,5,3]#number of clusters to be created\n",
    "dico_closest = {}\n",
    "for k in range (len(df_list)) : #clustering the entire set of twentiles for both TTC and spacing\n",
    "    results, centers, closest = clustering_data(df_list[k],nb_cluster_list[k])\n",
    "    cluster_DataFrame_kmeans[name_columns[k] + '_cluster']= results['label']\n",
    "    dico_closest[name_columns[k]] = closest\n",
    "cluster_DataFrame_kmeans.set_index('scenario',inplace=True)\n",
    "for k in cluster_DataFrame.columns : \n",
    "    cluster_DataFrame_kmeans[k] = cluster_DataFrame_kmeans[k].astype(float)\n",
    "cluster_DataFrame_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b588ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_distribution(indicator, cluster_df, cluster_number, indicator_df) : \n",
    "    \"\"\"\"input indicator to be plotted, dataframe that describes the cluster number, list of cluster names\n",
    "        for this indicator, dataframe that contains the twentiles for this indicator\"\"\"\n",
    "    sample_number = len(cluster_df[indicator+'_cluster']) #computing the importion in percentage of each cluster\n",
    "    count_df = pd.DataFrame(cluster_df[indicator+'_cluster'].value_counts())\n",
    "    count_df.sort_index(axis=0, inplace = True)\n",
    "    count_df['percentage'] = count_df[indicator+'_cluster']/sample_number*100\n",
    "    y_list = [k for k in range(1,21)]\n",
    "    plt.rcParams['figure.figsize'] = (20, 15)\n",
    "    custom_lines = []\n",
    "    palette = itertools.cycle(sns.color_palette())\n",
    "    legend_elements = []\n",
    "    for cluster in cluster_number : \n",
    "        color=next(palette)\n",
    "        df_out = pd.DataFrame()\n",
    "        for k in tqdm_notebook ( range(len(cluster_df[indicator+'_cluster']))):\n",
    "            if cluster_df[indicator+'_cluster'][k]==cluster :\n",
    "                try :\n",
    "                    liste = list(indicator_df[cluster_df.index[k]])\n",
    "                    plt.plot(liste, y_list, color = color, alpha=0.3) #plotting the twentiles belonging to the cluster\n",
    "                except KeyError :\n",
    "                    continue\n",
    "        legend_elements.append(Line2D([0], [0], color=color, lw=4, label='cluster ' + str (cluster)+\n",
    "                                     ' (' + str(round(count_df['percentage'][cluster],2)) + '% of samples)'))\n",
    "        #creating a legend with the cluster number and its sample share\n",
    "    plt.ylabel('twentile', size = 25)       \n",
    "    plt.xlabel('TTC (s)', size = 25)    \n",
    "    plt.legend(handles=legend_elements, loc='best', prop={'size': 25})\n",
    "    plt.title(indicator + ' twentile distribution and clusters', size = 45)\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6661fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_distribution('EIDM spacing',cluster_DataFrame_kmeans , [0, 1, 2, 3 ,4],DataFrame_EIDM_spacing )\n",
    "plot_cluster_distribution('EIDM TTC',cluster_DataFrame_kmeans , [0, 1, 2],DataFrame_EIDM_TTC)\n",
    "plot_cluster_distribution('Krauss spacing',cluster_DataFrame_kmeans , [0, 1, 2, 3 ,4],DataFrame_Krauss_spacing)\n",
    "plot_cluster_distribution('Krauss TTC',cluster_DataFrame_kmeans , [0, 1, 2],DataFrame_Krauss_TTC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af280a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#plot heatmaps\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m figA \u001b[38;5;241m=\u001b[39m \u001b[43mpx\u001b[49m\u001b[38;5;241m.\u001b[39mdensity_heatmap(cluster_DataFrame_kmeans, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEIDM spacing_cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKrauss spacing_cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                          marginal_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistogram\u001b[39m\u001b[38;5;124m\"\u001b[39m, marginal_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistogram\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m                           text_auto\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m                           labels\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      6\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEIDM spacing_cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEIDM spacing cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKrauss spacing_cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKrauss spacing cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m                  },\n\u001b[0;32m      9\u001b[0m                 title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheatmap of the spacing clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m                         )\n\u001b[0;32m     11\u001b[0m figB \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mdensity_heatmap(cluster_DataFrame_kmeans, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEIDM TTC_cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKrauss TTC_cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m                          marginal_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistogram\u001b[39m\u001b[38;5;124m\"\u001b[39m, marginal_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistogram\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m                           text_auto \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheatmap of the TTC clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m                          )\n\u001b[0;32m     20\u001b[0m figA\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "#plot heatmaps\n",
    "figA = px.density_heatmap(cluster_DataFrame_kmeans, x=\"EIDM spacing_cluster\", y=\"Krauss spacing_cluster\",\n",
    "                         marginal_x=\"histogram\", marginal_y=\"histogram\",\n",
    "                          text_auto=True,\n",
    "                          labels={\n",
    "                     \"EIDM spacing_cluster\": \"EIDM spacing cluster\",\n",
    "                     \"Krauss spacing_cluster\": \"Krauss spacing cluster\"\n",
    "                 },\n",
    "                title=\"heatmap of the spacing clusters\"\n",
    "                        )\n",
    "figB = px.density_heatmap(cluster_DataFrame_kmeans, x=\"EIDM TTC_cluster\", y=\"Krauss TTC_cluster\",\n",
    "                         marginal_x=\"histogram\", marginal_y=\"histogram\",\n",
    "                          text_auto =True,\n",
    "                          labels={\n",
    "                     \"EIDM TTC_cluster\": \"EIDM TTC cluster\",\n",
    "                     \"Krauss TTC_cluster\": \"Krauss TTC cluster\"\n",
    "                 },\n",
    "                title=\"heatmap of the TTC clusters\"\n",
    "                         )\n",
    "figA.show()\n",
    "figB.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed75cb15",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> HCA clustering </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2a4f9f",
   "metadata": {},
   "source": [
    "We compute a HCA clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of dendrograms to determine the number of clusters we have to compute\n",
    "# Plot title\n",
    "plt.title('Hierarchical Clustering Dendrogram EIDM spacing')\n",
    "\n",
    "# Plot axis labels\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance (Ward)')\n",
    "\n",
    "# Make the dendrogram\n",
    "dendrogram(ZsEIDM, labels=df_EIDM_spacing.T.index, leaf_rotation=90)\n",
    "\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot title\n",
    "plt.title('Hierarchical Clustering Dendrogram EIDM TTC')\n",
    "\n",
    "# Plot axis labels\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance (Ward)')\n",
    "\n",
    "# Make the dendrogram\n",
    "dendrogram(ZTTCEIDM, labels=df_EIDM_TTC.T.index, leaf_rotation=90)\n",
    "\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot title\n",
    "plt.title('Hierarchical Clustering Dendrogram Krauss spacing')\n",
    "\n",
    "# Plot axis labels\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance (Ward)')\n",
    "\n",
    "# Make the dendrogram\n",
    "dendrogram(Zskrauss, labels=df_Krauss_spacing.T.index, leaf_rotation=90)\n",
    "\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot title\n",
    "plt.title('Hierarchical Clustering Dendrogram Krauss TTC')\n",
    "\n",
    "# Plot axis labels\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance (Ward)')\n",
    "\n",
    "# Make the dendrogram\n",
    "dendrogram(ZTTCkrauss, labels=df_Krauss_TTC.T.index, leaf_rotation=90)\n",
    "\n",
    "# Show the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f271d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we wan cluster the different clusters using the cluster numbers that our dendrograms gave us\n",
    "df_list = [df_EIDM_spacing, df_EIDM_TTC, df_Krauss_spacing, df_Krauss_TTC]\n",
    "name_columns = ['EIDM spacing', 'EIDM TTC','Krauss spacing', 'Krauss TTC']\n",
    "names = list(DataFrame_EIDM_spacing.T.index)\n",
    "dendrogram_cluster_DataFrame= pd.DataFrame(names)\n",
    "dendrogram_cluster_DataFrame.columns = ['scenario']\n",
    "dendrogram_list = [5,7,5,7] #number of clusters to be created based on the dendrograms\n",
    "dico_closest = {}\n",
    "for k in range (len(df_list)) : \n",
    "    X = df_list[k].T\n",
    "    cluster = AgglomerativeClustering(n_clusters=dendrogram_list[k], affinity='euclidean', linkage='ward')\n",
    "    cluster.fit_predict(X)\n",
    "    dendrogram_cluster_DataFrame[name_columns[k] + '_cluster']= cluster.labels_\n",
    "dendrogram_cluster_DataFrame.set_index('scenario',inplace=True)\n",
    "for k in dendrogram_cluster_DataFrame.columns : \n",
    "    dendrogram_cluster_DataFrame[k] = dendrogram_cluster_DataFrame[k].astype(float)\n",
    "dendrogram_cluster_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705521e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting heatmaps \n",
    "figA = px.density_heatmap(dendrogram, x=\"EIDM spacing_cluster\", y=\"Krauss spacing_cluster\",\n",
    "                         marginal_x=\"histogram\", marginal_y=\"histogram\",\n",
    "                          text_auto=True,\n",
    "                          labels={\n",
    "                     \"EIDM spacing_cluster\": \"EIDM spacing cluster\",\n",
    "                     \"Krauss spacing_cluster\": \"Krauss spacing cluster\"\n",
    "                 },\n",
    "                title=\"heatmap of the spacing clusters for the HCA\"\n",
    "                        )\n",
    "figB = px.density_heatmap(dendrogram, x=\"EIDM TTC_cluster\", y=\"Krauss TTC_cluster\",\n",
    "                         marginal_x=\"histogram\", marginal_y=\"histogram\",\n",
    "                          text_auto =True,\n",
    "                          labels={\n",
    "                     \"EIDM TTC_cluster\": \"EIDM TTC cluster\",\n",
    "                     \"Krauss TTC_cluster\": \"Krauss TTC cluster\"\n",
    "                 },\n",
    "                title=\"heatmap of the TTC clusters for the HCA\"\n",
    "                         )\n",
    "figA.show()\n",
    "figB.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
